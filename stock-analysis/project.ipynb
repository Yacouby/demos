{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stocks Analysis Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stocks project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project name: stocks4-dani\n",
      "Artifacts path: v3io:///projects/{{run.project}}/artifacts\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "import os\n",
    "import mlrun\n",
    "\n",
    "# Set the base project name\n",
    "project_name_base = 'stocks4'\n",
    "# Initialize the MLRun environment and save the project name and artifacts path\n",
    "project_name, artifact_path = mlrun.set_environment(project=project_name_base,\n",
    "                                                    user_project=True)\n",
    "\n",
    "project_path = path.abspath('./')\n",
    "\n",
    "project = mlrun.new_project(project_name_base,\n",
    "                            context=project_path,                           \n",
    "                            user_project=True)\n",
    "                                                    \n",
    "# Display the current project name and artifacts path\n",
    "print(f'Project name: {project_name}')\n",
    "print(f'Artifacts path: {artifact_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare project functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import mount_v3io, code_to_function\n",
    "# Set functions to project\n",
    "project.set_function('code/00-train-sentiment-analysis-model.ipynb', name='bert_sentiment_classifier_trainer')\n",
    "project.set_function('code/01-read-stocks.ipynb', name='stocks_reader')\n",
    "project.set_function('code/02-read-news.ipynb', name='news_reader')\n",
    "project.set_function('code/03-stream-viewer.ipynb', name='stream_viewer')\n",
    "#mlrun.mlconf.hub_url = 'https://raw.githubusercontent.com/mlrun/functions/development/sentiment_analysis_serving/function.yaml'\n",
    "project.set_function('hub://sentiment_analysis_serving', name='sentiment_analysis_server')\n",
    "project.set_function('code/06-read-vector.ipynb', name='vector_reader')\n",
    "project.set_function(\"code/07-grafana.ipynb\", name='grafana_view')\n",
    "\n",
    "project.set_function(\"code/model_training.ipynb\", name='rnn_model_training')\n",
    "\n",
    "project.func('sentiment_analysis_server').apply(mount_v3io())\n",
    "# Declaring project name for later use\n",
    "project.spec.params = {}\n",
    "project.spec.params[\"PROJECT_NAME\"] = project_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a pre-trained model (optional)\n",
    "Since running the [training](training/bert_sentiment_classification.ipynb) part to achieve good results may take some time, we had already trained and uploaded a model to a public location.  \n",
    "You can easily download it by running the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to change the location of the source data, set the `SAMPLE_DATA_SOURCE_URL_PREFIX` environment variable.\n",
    "\n",
    "For example, set it to `/v3io/projects/demos-data/iguazio/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘/User/test/demos/stock-analysis/models/model.pt’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this to download the pre-trained model to your `models` directory\n",
    "url_prefix = os.environ.get('SAMPLE_DATA_SOURCE_URL_PREFIX', 'https://s3.wasabisys.com/iguazio/')\n",
    "\n",
    "import os\n",
    "model_location = f'{url_prefix.rstrip(\"/\")}/data/stock-analysis/model.pt'\n",
    "saved_models_directory = os.path.join(os.path.abspath('./'), 'models')\n",
    "\n",
    "# Create paths\n",
    "os.makedirs(saved_models_directory, exist_ok=1)\n",
    "model_filepath = os.path.join(saved_models_directory, os.path.basename(model_location))\n",
    "\n",
    "if \"http\" in model_location:\n",
    "    ! wget -nc -P {saved_models_directory} {model_location}\n",
    "else:\n",
    "    ! cp {model_location} {saved_models_directory}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.serving.states.TaskStep at 0x7f55ff685210>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add model \n",
    "project.func('sentiment_analysis_server').add_model(\"model1\", class_name='SentimentClassifierServing', model_path=model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create deployment workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/workflow.py\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io, mlconf, load_project\n",
    "import os\n",
    "from nuclio.triggers import V3IOStreamTrigger, CronTrigger\n",
    "import re \n",
    "\n",
    "funcs = {}\n",
    "\n",
    "# Directories and Paths\n",
    "projdir = os.path.abspath('./')\n",
    "project = load_project(projdir)\n",
    "project_name = project.spec.params.get(\"PROJECT_NAME\")\n",
    "model_filepath = os.path.join(projdir, 'models', 'model.pt') # Previously saved model if downloaded\n",
    "reviews_datafile = os.path.join(projdir, 'data', 'reviews.csv')\n",
    "# Performence limit\n",
    "max_replicas = 1\n",
    "\n",
    "# Readers cron interval\n",
    "readers_cron_interval = '300s'\n",
    "\n",
    "# Training GPU Allocation\n",
    "# Set to 0 if no gpus are to be used\n",
    "training_gpus = 0\n",
    "\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    for f in functions.values():\n",
    "        # Add V3IO Mount\n",
    "        f.apply(mount_v3io())\n",
    "        \n",
    "        # Always pull images to keep updates\n",
    "        f.spec.image_pull_policy = 'Always'\n",
    "    \n",
    "    # Define inference-stream related triggers\n",
    "#     functions['sentiment_analysis_server'].add_model('bert_classifier_v1', model_filepath)\n",
    "    functions['sentiment_analysis_server'].spec.readiness_timeout = 500\n",
    "    functions['sentiment_analysis_server'].set_config('readinessTimeoutSeconds', 500)\n",
    "    \n",
    "    # Adept image to use CPU if a GPU is not assigned\n",
    "    if training_gpus == 0:\n",
    "        functions['sentiment_analysis_server'].spec.base_spec['spec']['build']['baseImage']='mlrun/ml-models'\n",
    "        functions['bert_sentiment_classifier_trainer'].spec.image='mlrun/ml-models'\n",
    "    \n",
    "    # Add triggers\n",
    "    functions['stocks_reader'].add_trigger('cron', CronTrigger(readers_cron_interval))\n",
    "    functions['news_reader'].add_trigger('cron', CronTrigger(readers_cron_interval))\n",
    "    \n",
    "    \n",
    "    # Set max replicas for resource limits\n",
    "    functions['sentiment_analysis_server'].spec.max_replicas = max_replicas\n",
    "    functions['news_reader'].spec.max_replicas = max_replicas\n",
    "    functions['stocks_reader'].spec.max_replicas = max_replicas\n",
    "    \n",
    "    # Add GPU for training\n",
    "    functions['bert_sentiment_classifier_trainer'].gpus(training_gpus)\n",
    "        \n",
    "@dsl.pipeline(\n",
    "    name='Stocks demo deployer',\n",
    "    description='Up to RT Stocks ingestion and analysis'\n",
    ")\n",
    "def kfpipeline(\n",
    "    # General\n",
    "    V3IO_CONTAINER = 'users',\n",
    "    STOCKS_TSDB_TABLE = os.getenv('V3IO_USERNAME') + '/stocks/stocks_tsdb',\n",
    "    STOCKS_KV_TABLE = os.getenv('V3IO_USERNAME') + '/stocks/stocks_kv',\n",
    "    STOCKS_STREAM = os.getenv('V3IO_USERNAME') + '/stocks/stocks_stream',\n",
    "    RUN_TRAINER: bool = False,\n",
    "    \n",
    "    # Trainer\n",
    "    pretrained_model = 'bert-base-cased',\n",
    "    reviews_dataset = reviews_datafile,\n",
    "    models_dir = 'models',\n",
    "    model_filename = 'bert_sentiment_analysis_model.pt',\n",
    "    n_classes: int = 3,\n",
    "    MAX_LEN: int = 128,\n",
    "    BATCH_SIZE: int = 16,\n",
    "    EPOCHS: int =  2,\n",
    "    random_state: int = 42,\n",
    "    \n",
    "    # stocks reader\n",
    "    STOCK_LIST: list = ['GOOGL', 'MSFT', 'AMZN', 'AAPL', 'INTC'],\n",
    "    EXPRESSION_TEMPLATE = \"symbol='{symbol}';price={price};volume={volume};last_updated='{last_updated}'\",\n",
    "    \n",
    "    # Sentiment analysis server\n",
    "    model_name = 'bert_classifier_v1',\n",
    "    model_filepath = model_filepath # if not trained\n",
    "    \n",
    "    ):\n",
    "    \n",
    "    with dsl.Condition(RUN_TRAINER == True):\n",
    "        \n",
    "        deployer = funcs['bert_sentiment_classifier_trainer'].deploy_step()\n",
    "                \n",
    "        trainer = funcs['bert_sentiment_classifier_trainer'].as_step(name='bert_sentiment_classifier_trainer',\n",
    "                                                                     handler='train_sentiment_analysis_model',\n",
    "                                                                     params={'pretrained_model': pretrained_model,\n",
    "                                                                             'EPOCHS': EPOCHS,\n",
    "                                                                             'models_dir': models_dir,\n",
    "                                                                             'model_filename': model_filename,\n",
    "                                                                             'n_classes': n_classes,\n",
    "                                                                             'MAX_LEN': MAX_LEN,\n",
    "                                                                             'BATCH_SIZE': BATCH_SIZE,\n",
    "                                                                             'EPOCHS': EPOCHS,\n",
    "                                                                             'random_state': random_state},\n",
    "                                                                     inputs={'reviews_dataset': reviews_dataset},\n",
    "                                                                     outputs=['bert_sentiment_analysis_model'],\n",
    "                                                                     image=deployer.outputs['image'])\n",
    "        #becasue we switched to V2_Model_Server, no need to send model filepath as env variable\n",
    "        sentiment_server = funcs['sentiment_analysis_server'].deploy_step()#env={f'SERVING_MODEL_{model_name}': trainer.outputs['bert_sentiment_analysis_model']}\n",
    "        \n",
    "        news_reader = funcs['news_reader'].deploy_step(env={'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_STREAM': STOCKS_STREAM,\n",
    "                                                            'STOCKS_TSDB_TABLE': STOCKS_TSDB_TABLE,\n",
    "                                                            'SENTIMENT_MODEL_ENDPOINT': sentiment_server.outputs['endpoint'],\n",
    "                                                           'PROJECT_NAME' : project_name})\n",
    "    \n",
    "    with dsl.Condition(RUN_TRAINER == False):\n",
    "        #becasue we switched to V2_Model_Server, no need to send model filepath as env variable\n",
    "        sentiment_server = funcs['sentiment_analysis_server'].deploy_step() #env={f'SERVING_MODEL_{model_name}': model_filepath}\n",
    "        \n",
    "        news_reader = funcs['news_reader'].deploy_step(env={'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_STREAM': STOCKS_STREAM,\n",
    "                                                            'STOCKS_TSDB_TABLE': STOCKS_TSDB_TABLE,\n",
    "                                                            'SENTIMENT_MODEL_ENDPOINT': sentiment_server.outputs['endpoint'],\n",
    "                                                           'PROJECT_NAME' : project_name})\n",
    "    \n",
    "    stocks_reader = funcs['stocks_reader'].deploy_step(env={'STOCK_LIST': STOCK_LIST,\n",
    "                                                            'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_TSDB_TABLE': STOCKS_TSDB_TABLE,\n",
    "                                                            'STOCKS_KV_TABLE': STOCKS_KV_TABLE,\n",
    "                                                            'EXPRESSION_TEMPLATE': EXPRESSION_TEMPLATE,\n",
    "                                                           'PROJECT_NAME' : project_name})\n",
    "    \n",
    "    stream_viewer = funcs['stream_viewer'].deploy_step(env={'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_STREAM': STOCKS_STREAM}).after(news_reader)\n",
    "    \n",
    "    vector_viewer = funcs['vector_reader'].deploy_step(env={'PROJECT_NAME' : project_name}).after(news_reader)\n",
    "    \n",
    "    grafana_viewer = funcs[\"grafana_view\"].deploy_step()\n",
    "    \n",
    "    grafana_viewer = funcs[\"grafana_view\"].as_step(params = {\"streamview_url\" : stream_viewer.outputs[\"endpoint\"],\n",
    "                                                             \"readvector_url\" : vector_viewer.outputs[\"endpoint\"],\n",
    "                                                             \"v3io_container\" : V3IO_CONTAINER,\n",
    "                                                             \"stocks_kv\" : STOCKS_KV_TABLE,\n",
    "                                                             \"stocks_tsdb\" : STOCKS_TSDB_TABLE,\n",
    "                                                             \"grafana_url\" : \"http://grafana\"},\n",
    "                                                   handler = \"handler\").after(grafana_viewer)\n",
    "    \n",
    "    rnn_model_training_deployer = funcs[\"rnn_model_training\"].deploy_step(env={'model_path': os.getcwd()+\"/code/mymodel2.h5\"})\n",
    "    rnn_model_training_run = funcs[\"rnn_model_training\"].as_step(handler=\"handler\").after(vector_viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_workflow('main', os.path.join(os.path.abspath(project.context), 'code', 'workflow.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save(os.path.join(project.context, 'project.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run workflow\n",
    "In this cell we will run the `main` workflow via `KubeFlow Pipelines` on top of our cluster.  \n",
    "Running the pipeline may take some time. Due to possible jupyter timeout, it's best to track the pipeline's progress via KFP or the MLRun UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MLRunUnauthorizedError",
     "evalue": "401 Client Error: Unauthorized for url: http://mlrun-api:8080/api/func/stocks4-dani/bert-sentiment-classifier-trainer?tag=&versioned=True: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/errors.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(response, message)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: http://mlrun-api:8080/api/func/stocks4-dani/bert-sentiment-classifier-trainer?tag=&versioned=True",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMLRunUnauthorizedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-81ecdba58a11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'main'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'RUN_TRAINER'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/projects/project.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, name, workflow_path, arguments, artifact_path, namespace, sync, watch, dirty, ttl)\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m             \u001b[0mttl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mttl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m         )\n\u001b[1;32m   1326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/projects/project.py\u001b[0m in \u001b[0;36m_run_pipeline\u001b[0;34m(project, name, pipeline, functions, secrets, arguments, artifact_path, namespace, ttl)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m         \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m         \u001b[0mttl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mttl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m     )\n\u001b[1;32m   1858\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/run.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(pipeline, arguments, project, experiment, run, namespace, artifact_path, ops, url, ttl)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m                 \u001b[0mpipeline_conf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m             )\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/lib/python3.7/site-packages/kfp/_client.py\u001b[0m in \u001b[0;36mcreate_run_from_pipeline_func\u001b[0;34m(self, pipeline_func, arguments, run_name, experiment_name, pipeline_conf, namespace)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTemporaryDirectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmpdir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m       \u001b[0mpipeline_package_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pipeline.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m       \u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_package_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_conf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_run_from_pipeline_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_package_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/lib/python3.7/site-packages/kfp/compiler/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, pipeline_func, package_path, type_check, pipeline_conf)\u001b[0m\n\u001b[1;32m    903\u001b[0m           \u001b[0mpipeline_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m           \u001b[0mpipeline_conf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_conf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m           package_path=package_path)\n\u001b[0m\u001b[1;32m    906\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       \u001b[0mkfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTYPE_CHECK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_check_old_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/lib/python3.7/site-packages/kfp/compiler/compiler.py\u001b[0m in \u001b[0;36m_create_and_write_workflow\u001b[0;34m(self, pipeline_func, pipeline_name, pipeline_description, params_list, pipeline_conf, package_path)\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mpipeline_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0mparams_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         pipeline_conf)\n\u001b[0m\u001b[1;32m    961\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_workflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0m_validate_workflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/lib/python3.7/site-packages/kfp/compiler/compiler.py\u001b[0m in \u001b[0;36m_create_workflow\u001b[0;34m(self, pipeline_func, pipeline_name, pipeline_description, params_list, pipeline_conf)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mdsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdsl_pipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m       \u001b[0mpipeline_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0mpipeline_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_conf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdsl_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;31m# Configuration passed to the compiler is overriding. Unfortunately, it's not trivial to detect whether the dsl_pipeline.conf was ever modified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test/demos/stock-analysis/code/workflow.py\u001b[0m in \u001b[0;36mkfpipeline\u001b[0;34m(V3IO_CONTAINER, STOCKS_TSDB_TABLE, STOCKS_KV_TABLE, STOCKS_STREAM, RUN_TRAINER, pretrained_model, reviews_dataset, models_dir, model_filename, n_classes, MAX_LEN, BATCH_SIZE, EPOCHS, random_state, STOCK_LIST, EXPRESSION_TEMPLATE, model_name, model_filepath)\u001b[0m\n\u001b[1;32m    104\u001b[0m                                                                      \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'reviews_dataset'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreviews_dataset\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                                                                      \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bert_sentiment_analysis_model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                                                                      image=deployer.outputs['image'])\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;31m#becasue we switched to V2_Model_Server, no need to send model filepath as env variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0msentiment_server\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment_analysis_server'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#env={f'SERVING_MODEL_{model_name}': trainer.outputs['bert_sentiment_analysis_model']}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/runtimes/base.py\u001b[0m in \u001b[0;36mas_step\u001b[0;34m(self, runspec, handler, name, project, params, hyperparams, selector, hyper_param_options, inputs, outputs, workdir, artifact_path, image, labels, use_db, verbose, scrape_metrics)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_db\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversioned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/runtimes/base.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, tag, versioned, refresh)\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"saving function: {self.metadata.name}, tag: {tag}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         hash_key = db.store_function(\n\u001b[0;32m--> 870\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversioned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         )\n\u001b[1;32m    872\u001b[0m         \u001b[0mhash_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_key\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mversioned\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/db/httpdb.py\u001b[0m in \u001b[0;36mstore_function\u001b[0;34m(self, function, name, project, tag, versioned)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"store function {project}/{name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         resp = self.api_call(\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         )\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/db/httpdb.py\u001b[0m in \u001b[0;36mapi_call\u001b[0;34m(self, method, path, error, params, body, json, headers, timeout)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mmlrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mmlrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/errors.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(response, message)\u001b[0m\n\u001b[1;32m     63\u001b[0m             raise STATUS_ERRORS[response.status_code](\n\u001b[1;32m     64\u001b[0m                 \u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             ) from exc\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mMLRunHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMLRunUnauthorizedError\u001b[0m: 401 Client Error: Unauthorized for url: http://mlrun-api:8080/api/func/stocks4-dani/bert-sentiment-classifier-trainer?tag=&versioned=True: None"
     ]
    }
   ],
   "source": [
    "project.run('main', arguments={'RUN_TRAINER': False}, artifact_path=artifact_path, dirty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
