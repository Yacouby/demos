{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stocks Analysis Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stocks project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project name: stocks-dani\n",
      "Artifacts path: v3io:///projects/{{run.project}}/artifacts\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "import os\n",
    "import mlrun\n",
    "\n",
    "# Set the base project name\n",
    "project_name_base = 'stocks'\n",
    "# Initialize the MLRun environment and save the project name and artifacts path\n",
    "project_name, artifact_path = mlrun.set_environment(project=project_name_base,\n",
    "                                                    user_project=True)\n",
    "\n",
    "project_path = path.abspath('./')\n",
    "\n",
    "project = mlrun.new_project(project_name_base,\n",
    "                            context=project_path,                           \n",
    "                            user_project=True)\n",
    "                                                    \n",
    "# Display the current project name and artifacts path\n",
    "print(f'Project name: {project_name}')\n",
    "print(f'Artifacts path: {artifact_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare project functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import mount_v3io, code_to_function\n",
    "# Set functions to project\n",
    "project.set_function('code/00-train-sentiment-analysis-model.ipynb', name='bert_sentiment_classifier_trainer')\n",
    "project.set_function('code/01-read-stocks.ipynb', name='stocks_reader')\n",
    "project.set_function('code/02-read-news.ipynb', name='news_reader')\n",
    "project.set_function('code/03-stream-viewer.ipynb', name='stream_viewer')\n",
    "#mlrun.mlconf.hub_url = 'https://raw.githubusercontent.com/mlrun/functions/development/sentiment_analysis_serving/function.yaml'\n",
    "project.set_function('hub://sentiment_analysis_serving', name='sentiment_analysis_server')\n",
    "project.set_function('code/06-read-vector.ipynb', name='vector_reader')\n",
    "project.set_function(\"code/07-grafana.ipynb\", name='grafana_view')\n",
    "\n",
    "project.func('sentiment_analysis_server').apply(mount_v3io())\n",
    "# Declaring project name for later use\n",
    "project.spec.params = {}\n",
    "project.spec.params[\"PROJECT_NAME\"] = project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a pre-trained model (optional)\n",
    "Since running the [training](training/bert_sentiment_classification.ipynb) part to achieve good results may take some time, we had already trained and uploaded a model to a public location.  \n",
    "You can easily download it by running the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to change the location of the source data, set the `SAMPLE_DATA_SOURCE_URL_PREFIX` environment variable.\n",
    "\n",
    "For example, set it to `/v3io/projects/demos-data/iguazio/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-23 09:57:36--  https://s3.wasabisys.com/iguazio/data/stock-analysis/model.pt\n",
      "Resolving s3.wasabisys.com (s3.wasabisys.com)... 38.27.106.51, 38.27.106.53\n",
      "Connecting to s3.wasabisys.com (s3.wasabisys.com)|38.27.106.51|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 433298364 (413M) [application/octet-stream]\n",
      "Saving to: ‘/User/test/demos/stock-analysis/models/model.pt’\n",
      "\n",
      "model.pt            100%[===================>] 413.22M  6.92MB/s    in 73s     \n",
      "\n",
      "2021-06-23 09:58:51 (5.66 MB/s) - ‘/User/test/demos/stock-analysis/models/model.pt’ saved [433298364/433298364]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this to download the pre-trained model to your `models` directory\n",
    "url_prefix = os.environ.get('SAMPLE_DATA_SOURCE_URL_PREFIX', 'https://s3.wasabisys.com/iguazio/')\n",
    "\n",
    "import os\n",
    "model_location = f'{url_prefix.rstrip(\"/\")}/data/stock-analysis/model.pt'\n",
    "saved_models_directory = os.path.join(os.path.abspath('./'), 'models')\n",
    "\n",
    "# Create paths\n",
    "os.makedirs(saved_models_directory, exist_ok=1)\n",
    "model_filepath = os.path.join(saved_models_directory, os.path.basename(model_location))\n",
    "\n",
    "if \"http\" in model_location:\n",
    "    ! wget -nc -P {saved_models_directory} {model_location}\n",
    "else:\n",
    "    ! cp {model_location} {saved_models_directory}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.serving.states.TaskStep at 0x7efdf7ccfbd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add model \n",
    "project.func('sentiment_analysis_server').add_model(\"model1\", class_name='SentimentClassifierServing', model_path=model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create deployment workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/workflow.py\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io, mlconf, load_project\n",
    "import os\n",
    "from nuclio.triggers import V3IOStreamTrigger, CronTrigger\n",
    "import re \n",
    "\n",
    "funcs = {}\n",
    "\n",
    "# Directories and Paths\n",
    "projdir = os.path.abspath('./')\n",
    "project = load_project(projdir)\n",
    "project_name = project.spec.params.get(\"PROJECT_NAME\")\n",
    "model_filepath = os.path.join(projdir, 'models', 'model.pt') # Previously saved model if downloaded\n",
    "reviews_datafile = os.path.join(projdir, 'data', 'reviews.csv')\n",
    "# Performence limit\n",
    "max_replicas = 1\n",
    "\n",
    "# Readers cron interval\n",
    "readers_cron_interval = '300s'\n",
    "\n",
    "# Training GPU Allocation\n",
    "# Set to 0 if no gpus are to be used\n",
    "training_gpus = 0\n",
    "\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    for f in functions.values():\n",
    "        # Add V3IO Mount\n",
    "        f.apply(mount_v3io())\n",
    "        \n",
    "        # Always pull images to keep updates\n",
    "        f.spec.image_pull_policy = 'Always'\n",
    "    \n",
    "    # Define inference-stream related triggers\n",
    "    functions['sentiment_analysis_server'].add_model('bert_classifier_v1', model_filepath)\n",
    "    functions['sentiment_analysis_server'].spec.readiness_timeout = 500\n",
    "    functions['sentiment_analysis_server'].set_config('readinessTimeoutSeconds', 500)\n",
    "    \n",
    "    # Adept image to use CPU if a GPU is not assigned\n",
    "    if training_gpus == 0:\n",
    "        functions['sentiment_analysis_server'].spec.base_spec['spec']['build']['baseImage']='mlrun/ml-models'\n",
    "        functions['bert_sentiment_classifier_trainer'].spec.image='mlrun/ml-models'\n",
    "    \n",
    "    # Add triggers\n",
    "    functions['stocks_reader'].add_trigger('cron', CronTrigger(readers_cron_interval))\n",
    "    functions['news_reader'].add_trigger('cron', CronTrigger(readers_cron_interval))\n",
    "    \n",
    "    \n",
    "    # Set max replicas for resource limits\n",
    "    functions['sentiment_analysis_server'].spec.max_replicas = max_replicas\n",
    "    functions['news_reader'].spec.max_replicas = max_replicas\n",
    "    functions['stocks_reader'].spec.max_replicas = max_replicas\n",
    "    \n",
    "    # Add GPU for training\n",
    "    functions['bert_sentiment_classifier_trainer'].gpus(training_gpus)\n",
    "        \n",
    "@dsl.pipeline(\n",
    "    name='Stocks demo deployer',\n",
    "    description='Up to RT Stocks ingestion and analysis'\n",
    ")\n",
    "def kfpipeline(\n",
    "    # General\n",
    "    V3IO_CONTAINER = 'users',\n",
    "    STOCKS_TSDB_TABLE = os.getenv('V3IO_USERNAME') + '/stocks/stocks_tsdb',\n",
    "    STOCKS_KV_TABLE = os.getenv('V3IO_USERNAME') + '/stocks/stocks_kv',\n",
    "    STOCKS_STREAM = os.getenv('V3IO_USERNAME') + '/stocks/stocks_stream',\n",
    "    RUN_TRAINER: bool = False,\n",
    "    \n",
    "    # Trainer\n",
    "    pretrained_model = 'bert-base-cased',\n",
    "    reviews_dataset = reviews_datafile,\n",
    "    models_dir = 'models',\n",
    "    model_filename = 'bert_sentiment_analysis_model.pt',\n",
    "    n_classes: int = 3,\n",
    "    MAX_LEN: int = 128,\n",
    "    BATCH_SIZE: int = 16,\n",
    "    EPOCHS: int =  2,\n",
    "    random_state: int = 42,\n",
    "    \n",
    "    # stocks reader\n",
    "    STOCK_LIST: list = ['GOOGL', 'MSFT', 'AMZN', 'AAPL', 'INTC'],\n",
    "    EXPRESSION_TEMPLATE = \"symbol='{symbol}';price={price};volume={volume};last_updated='{last_updated}'\",\n",
    "    \n",
    "    # Sentiment analysis server\n",
    "    model_name = 'bert_classifier_v1',\n",
    "    model_filepath = model_filepath # if not trained\n",
    "    \n",
    "    ):\n",
    "    \n",
    "    with dsl.Condition(RUN_TRAINER == True):\n",
    "        \n",
    "        deployer = funcs['bert_sentiment_classifier_trainer'].deploy_step()\n",
    "                \n",
    "        trainer = funcs['bert_sentiment_classifier_trainer'].as_step(name='bert_sentiment_classifier_trainer',\n",
    "                                                                     handler='train_sentiment_analysis_model',\n",
    "                                                                     params={'pretrained_model': pretrained_model,\n",
    "                                                                             'EPOCHS': EPOCHS,\n",
    "                                                                             'models_dir': models_dir,\n",
    "                                                                             'model_filename': model_filename,\n",
    "                                                                             'n_classes': n_classes,\n",
    "                                                                             'MAX_LEN': MAX_LEN,\n",
    "                                                                             'BATCH_SIZE': BATCH_SIZE,\n",
    "                                                                             'EPOCHS': EPOCHS,\n",
    "                                                                             'random_state': random_state},\n",
    "                                                                     inputs={'reviews_dataset': reviews_dataset},\n",
    "                                                                     outputs=['bert_sentiment_analysis_model'],\n",
    "                                                                     image=deployer.outputs['image'])\n",
    "        \n",
    "        sentiment_server = funcs['sentiment_analysis_server'].deploy_step(env={f'SERVING_MODEL_{model_name}': trainer.outputs['bert_sentiment_analysis_model']})\n",
    "        \n",
    "        news_reader = funcs['news_reader'].deploy_step(env={'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_STREAM': STOCKS_STREAM,\n",
    "                                                            'STOCKS_TSDB_TABLE': STOCKS_TSDB_TABLE,\n",
    "                                                            'SENTIMENT_MODEL_ENDPOINT': sentiment_server.outputs['endpoint'],\n",
    "                                                           'PROJECT_NAME' : project_name})\n",
    "    \n",
    "    with dsl.Condition(RUN_TRAINER == False):\n",
    "        \n",
    "        sentiment_server = funcs['sentiment_analysis_server'].deploy_step(env={f'SERVING_MODEL_{model_name}': model_filepath})\n",
    "        \n",
    "        news_reader = funcs['news_reader'].deploy_step(env={'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_STREAM': STOCKS_STREAM,\n",
    "                                                            'STOCKS_TSDB_TABLE': STOCKS_TSDB_TABLE,\n",
    "                                                            'SENTIMENT_MODEL_ENDPOINT': sentiment_server.outputs['endpoint'],\n",
    "                                                           'PROJECT_NAME' : project_name})\n",
    "    \n",
    "    stocks_reader = funcs['stocks_reader'].deploy_step(env={'STOCK_LIST': STOCK_LIST,\n",
    "                                                            'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_TSDB_TABLE': STOCKS_TSDB_TABLE,\n",
    "                                                            'STOCKS_KV_TABLE': STOCKS_KV_TABLE,\n",
    "                                                            'EXPRESSION_TEMPLATE': EXPRESSION_TEMPLATE,\n",
    "                                                           'PROJECT_NAME' : project_name})\n",
    "    \n",
    "    stream_viewer = funcs['stream_viewer'].deploy_step(env={'V3IO_CONTAINER': V3IO_CONTAINER,\n",
    "                                                            'STOCKS_STREAM': STOCKS_STREAM}).after(news_reader)\n",
    "    \n",
    "    vector_viewer = funcs['vector_reader'].deploy_step(env={'PROJECT_NAME' : project_name}).after(news_reader)\n",
    "    \n",
    "    grafana_viewer = funcs[\"grafana_view\"].deploy_step()\n",
    "    \n",
    "    grafana_viewer = funcs[\"grafana_view\"].as_step(params = {\"streamview_url\" : stream_viewer.outputs[\"endpoint\"],\n",
    "                                                             \"readvector_url\" : vector_viewer.outputs[\"endpoint\"],\n",
    "                                                             \"v3io_container\" : V3IO_CONTAINER,\n",
    "                                                             \"stocks_kv\" : STOCKS_KV_TABLE,\n",
    "                                                             \"stocks_tsdb\" : STOCKS_TSDB_TABLE,\n",
    "                                                             \"grafana_url\" : \"http://grafana\"},\n",
    "                                                   handler = \"handler\").after(grafana_viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_workflow('main', os.path.join(os.path.abspath(project.context), 'code', 'workflow.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MLRunUnauthorizedError",
     "evalue": "401 Client Error: Unauthorized for url: http://mlrun-api:8080/api/projects/stocks-dani: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/errors.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(response, message)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: http://mlrun-api:8080/api/projects/stocks-dani",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMLRunUnauthorizedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ea3a7fcb0958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'project.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/projects/project.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m   1401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/projects/project.py\u001b[0m in \u001b[0;36msave_to_db\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_run_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecrets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_secrets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/db/httpdb.py\u001b[0m in \u001b[0;36mstore_project\u001b[0;34m(self, name, project)\u001b[0m\n\u001b[1;32m   1736\u001b[0m             \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m         response = self.api_call(\n\u001b[0;32m-> 1738\u001b[0;31m             \u001b[0;34m\"PUT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1739\u001b[0m         )\n\u001b[1;32m   1740\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACCEPTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/db/httpdb.py\u001b[0m in \u001b[0;36mapi_call\u001b[0;34m(self, method, path, error, params, body, json, headers, timeout)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mmlrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mmlrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-dani/lib/python3.7/site-packages/mlrun/errors.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(response, message)\u001b[0m\n\u001b[1;32m     63\u001b[0m             raise STATUS_ERRORS[response.status_code](\n\u001b[1;32m     64\u001b[0m                 \u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             ) from exc\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mMLRunHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMLRunUnauthorizedError\u001b[0m: 401 Client Error: Unauthorized for url: http://mlrun-api:8080/api/projects/stocks-dani: None"
     ]
    }
   ],
   "source": [
    "project.save(os.path.join(project.context, 'project.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run workflow\n",
    "In this cell we will run the `main` workflow via `KubeFlow Pipelines` on top of our cluster.  \n",
    "Running the pipeline may take some time. Due to possible jupyter timeout, it's best to track the pipeline's progress via KFP or the MLRun UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.run('main', arguments={'RUN_TRAINER': False}, artifact_path=artifact_path, dirty=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
