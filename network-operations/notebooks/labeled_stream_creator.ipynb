{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeled Stream Creator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_path = os.path.abspath('../')\n",
    "base_stream_path = f'/users/' + os.environ['V3IO_USERNAME']+ f'{base_path[5:]}'\n",
    "data_path = os.path.join(base_path, 'data')\n",
    "src_path = os.path.join(base_path, 'src')\n",
    "streaming_path = os.path.join(base_stream_path, 'streaming')\n",
    "fs_streaming_path = os.path.join(base_path, 'streaming')\n",
    "\n",
    "os.environ['base_path'] = base_path\n",
    "os.environ['data_path'] = data_path\n",
    "os.environ['src_path'] = src_path\n",
    "os.environ['streaming_path'] = streaming_path\n",
    "os.environ['fs_streaming_path'] = os.path.join(base_path, 'streaming')\n",
    "\n",
    "os.environ['METRICS_TABLE'] = fs_streaming_path + '/metrics'\n",
    "os.environ['PREDICTIONS_TABLE'] = fs_streaming_path+'/predictions'\n",
    "os.environ['OUTPUT_STREAM'] = streaming_path+'/labeled_stream'\n",
    "os.environ['prediction_col'] = 'predictions'\n",
    "os.environ['label_col'] = 'is_error'\n",
    "os.environ['output_stream_shards'] = '1'\n",
    "os.environ['BATCHES_TO_GENERATE'] = '20'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import v3io\n",
    "import v3io.dataplane\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_path(mntpath=''):\n",
    "    if mntpath[0] == '/':\n",
    "        mntpath = mntpath[1:]\n",
    "    paths = mntpath.split('/')\n",
    "    container = paths[0]\n",
    "    subpath = ''\n",
    "    if len(paths) > 1:\n",
    "        subpath = mntpath[len(container):]\n",
    "    return container, subpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stream(context, path, shards=1):\n",
    "    # create a stream w shards\n",
    "    container, stream_path = split_path(path)\n",
    "    context.logger.info(f'Creating stream in Container: {container} & Path {stream_path}')\n",
    "    response = context.v3io_client.stream.create(container=container,\n",
    "                                        stream_path=stream_path, \n",
    "                                        shard_count=shards,\n",
    "                                        raise_for_status=v3io.dataplane.RaiseForStatus.never)\n",
    "    response.raise_for_status([409, 204])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_to_stream(context, stream_path, data):\n",
    "    def restructure_stream_event(context, event):\n",
    "        instances = [dict()]\n",
    "        for key in data.keys():\n",
    "            if key not in ['when', 'class', 'model', 'worker', 'hostname', context.prediction_col]:\n",
    "                instances[0].update({key: event.pop(key)})\n",
    "        event['request'] = {'instances': instances}\n",
    "        event['resp'] = [int(event.pop(context.prediction_col))]\n",
    "        return event\n",
    "    \n",
    "    records = json.loads(data.to_json(orient='records'))\n",
    "    records = [{'data': json.dumps(restructure_stream_event(context, record))} for record in records]\n",
    "    context.logger.info(f'Logging {len(records)} records, Record example: {records[0]}')\n",
    "    container, stream_path = split_path(stream_path)\n",
    "    # batch\n",
    "    step = 10\n",
    "    for idx in range(0, len(records), step):\n",
    "        response = context.v3io_client.put_records(container=container,\n",
    "                                                   path=stream_path, \n",
    "                                                   records=records[idx:idx+step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_parquet(context, table, files_to_select=1):\n",
    "    mpath = [os.path.join(table, file) for file in os.listdir(table) if file.endswith(('parquet', 'pq'))]\n",
    "    files_by_updated = sorted(mpath, key=os.path.getmtime, reverse=False)\n",
    "    context.logger.debug_with('Input', input_files=files_by_updated[:files_to_select])\n",
    "    dfs = pd.concat([pd.read_parquet(file) for file in files_by_updated[:files_to_select]])\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_context(context):\n",
    "    \n",
    "    # How many batches to create? (-1 will run forever)\n",
    "    batches_to_generate = int(os.getenv('BATCHES_TO_GENERATE', 20))\n",
    "    setattr(context, 'batches_to_generate', batches_to_generate)\n",
    "    setattr(context, 'batches_generated', 0)\n",
    "    \n",
    "    # Set env vars\n",
    "    setattr(context, 'metrics_table', os.environ['METRICS_TABLE'])\n",
    "    setattr(context, 'predictions_table', os.environ['PREDICTIONS_TABLE'])\n",
    "    setattr(context, 'output_stream', os.environ['OUTPUT_STREAM'])\n",
    "    setattr(context, 'timestamp_col', os.getenv('timestamp_col', 'when'))\n",
    "    setattr(context, 'orig_timestamp_col', os.getenv('orig_timestamp_col', 'timestamp'))\n",
    "    \n",
    "    v3io_client = v3io.dataplane.Client(logger_verbosity='DEBUG', transport_verbosity='DEBUG')\n",
    "#     v3io_client.stream.create(container='users', stream_path='/orz/mlrun-demos/demos/network-operations/streaming/labeled_stream', shard_count=1)\n",
    "    setattr(context, 'v3io_client', v3io_client)\n",
    "    create_stream(context, context.output_stream)\n",
    "    \n",
    "    setattr(context, 'label_col', os.environ['label_col'])\n",
    "    setattr(context, 'prediction_col', os.environ['prediction_col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(context, event):\n",
    "    \n",
    "    # Limit the number of generated batches to save cluster resources\n",
    "    # for people forgetting the demo running\n",
    "    if (context.batches_to_generate == -1) or (context.batches_generated <= context.batches_to_generate):\n",
    "        \n",
    "        metrics = get_data_parquet(context, context.metrics_table, 2).loc[:, context.label_col].astype('int')\n",
    "        metrics.index.names = list([name if name != context.orig_timestamp_col else context.timestamp_col for name in metrics.index.names])\n",
    "        predictions = get_data_parquet(context, context.predictions_table, 2)\n",
    "        context.logger.debug(f'Labeling metrics ({metrics.shape}) and predictions ({predictions.shape})')\n",
    "        context.logger.debug_with('Indexes', metrics_index=metrics.index.names, predictions_index=predictions.index.names)\n",
    "\n",
    "        print('metrics')\n",
    "        print(metrics.head())\n",
    "        print(type(metrics))\n",
    "        metrics = pd.DataFrame(metrics)\n",
    "        print('change')\n",
    "        print(type(metrics))\n",
    "        print(metrics.head())\n",
    "        print(metrics.index.names)\n",
    "\n",
    "        full_df = pd.merge(left=predictions, right=metrics, left_on=metrics.index.names, how='left', right_index=True)\n",
    "        full_df = full_df.reset_index()\n",
    "        context.logger.info(f'Fully labeled batch size is {full_df.shape}')\n",
    "        context.logger.info(f'Indexes: {list(full_df.index.names)}')\n",
    "        context.logger.info(f'Columns: {full_df.columns}')\n",
    "        context.logger.info_with('sample', full_df=full_df.head(1))    \n",
    "        push_to_stream(context, context.output_stream, full_df)\n",
    "        \n",
    "        # Update batches count\n",
    "        context.batches_generated += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python> 2021-10-03 14:49:45,141 [info] Creating stream in Container: users & Path /dani/test/demos/network-operations/streaming/labeled_stream\n",
      "2021-10-03 14:49:45,142 [debug] Tx: {'connection_idx': 0, 'method': 'POST', 'path': '/users/dani/test/demos/network-operations/streaming/labeled_stream/', 'headers': {'X-v3io-function': 'CreateStream', 'X-v3io-session-key': '5b4a006e-d1e7-4f0b-8101-3e35bba895e7', 'Content-Type': 'application/json'}, 'body': '{\"ShardCount\":1,\"RetentionPeriodHours\":24}'}\n",
      "2021-10-03 14:49:45,143 [debug] Rx: {'connection_idx': 0, 'status_code': 204, 'body': b''}\n"
     ]
    }
   ],
   "source": [
    "init_context(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = nuclio.Event(body='')\n",
    "out = handler(context, event)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from v3io.dataplane import Client\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3io_client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v3io_client.delete_stream(container='users', path='/admin/demos/network-operations/streaming/labeled_stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(path, shard='0', seek_type='EARLIEST', last=100):\n",
    "    # seek the shard to the first record in it\n",
    "    container, stream_path = split_path(path)\n",
    "    shard_path = os.path.join(stream_path, shard)\n",
    "    response = v3io_client.seek_shard(container=container,\n",
    "                                      path=shard_path, \n",
    "                                      seek_type=seek_type)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # get records, starting from the location we got from seek\n",
    "    response = v3io_client.get_records(container=container,\n",
    "                                       path=shard_path, \n",
    "                                       location=response.output.location)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    models = ['pagehinkley', 'eddm', 'ddm']\n",
    "    result_record = response.output.records\n",
    "    records = [json.loads(record.data) for record in result_record[:last]]\n",
    "    pprint(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'class': 'RandomForestClassifier',\n",
      "  'hostname': 'jupyter-dani-86575fbc89-k9xvr',\n",
      "  'model': 'netops_predictor_v1',\n",
      "  'request': {'instances': [{'company': 'Cisneros__Fuentes_and_Nelson',\n",
      "                             'cpu_utilization': 64.29,\n",
      "                             'cpu_utilization_is_error': False,\n",
      "                             'data_center': 'Vincent_Roads',\n",
      "                             'device': '0698161311745',\n",
      "                             'is_error_x': False,\n",
      "                             'is_error_y': None,\n",
      "                             'latency': 0.0,\n",
      "                             'latency_is_error': False,\n",
      "                             'packet_loss': 1.0,\n",
      "                             'packet_loss_is_error': False,\n",
      "                             'throughput': 226.29,\n",
      "                             'throughput_is_error': False}]},\n",
      "  'resp': [0],\n",
      "  'when': 1633335347249,\n",
      "  'worker': None},\n",
      " {'class': 'RandomForestClassifier',\n",
      "  'hostname': 'jupyter-dani-86575fbc89-k9xvr',\n",
      "  'model': 'netops_predictor_v1',\n",
      "  'request': {'instances': [{'company': 'Cisneros__Fuentes_and_Nelson',\n",
      "                             'cpu_utilization': 87.6,\n",
      "                             'cpu_utilization_is_error': False,\n",
      "                             'data_center': 'Vincent_Roads',\n",
      "                             'device': '3601170185739',\n",
      "                             'is_error_x': False,\n",
      "                             'is_error_y': None,\n",
      "                             'latency': 0.97,\n",
      "                             'latency_is_error': False,\n",
      "                             'packet_loss': 2.0,\n",
      "                             'packet_loss_is_error': False,\n",
      "                             'throughput': 219.37,\n",
      "                             'throughput_is_error': False}]},\n",
      "  'resp': [0],\n",
      "  'when': 1633335347249,\n",
      "  'worker': None}]\n"
     ]
    }
   ],
   "source": [
    "print_stream(context.output_stream, seek_type='EARLIEST', last=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import code_to_function, mount_v3io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7f5a6d669250>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = code_to_function('labeled-stream-creator',\n",
    "                      kind='nuclio',\n",
    "                      project='network-operations', image='mlrun/ml-models')\n",
    "fn.spec.build.commands = ['pip install v3io']\n",
    "fn.apply(mount_v3io())\n",
    "fn.add_trigger('cron', nuclio.triggers.CronTrigger(interval='1m'))\n",
    "fn.set_envs({'METRICS_TABLE' : fs_streaming_path + '/metrics',\n",
    "             'PREDICTIONS_TABLE' : fs_streaming_path+'/predictions',\n",
    "             'OUTPUT_STREAM' : streaming_path+'/labeled_stream',\n",
    "             'prediction_col' : 'predictions',\n",
    "             'label_col' : 'is_error',\n",
    "             'output_stream_shards' : '1',\n",
    "             'BATCHES_TO_GENERATE' : '20'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-10-04 12:35:59,631 [info] function spec saved to path: ../src/labeled_stream_creator.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7f5a6d669250>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.save()\n",
    "fn.export('../src/labeled_stream_creator.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-10-04 12:35:59,638 [info] Starting remote function deploy\n",
      "2021-10-04 12:35:59  (info) Deploying function\n",
      "2021-10-04 12:35:59  (info) Building\n",
      "2021-10-04 12:36:00  (info) Staging files and preparing base images\n",
      "2021-10-04 12:36:00  (info) Building processor image\n",
      "2021-10-04 12:36:01  (info) Build complete\n",
      "2021-10-04 12:36:07  (info) Function deploy complete\n",
      "> 2021-10-04 12:36:08,807 [info] successfully deployed function: {'internal_invocation_urls': ['nuclio-network-operations-labeled-stream-creator.default-tenant.svc.cluster.local:8080'], 'external_invocation_urls': ['default-tenant.app.dev8.lab.iguazeng.com:30367']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://default-tenant.app.dev8.lab.iguazeng.com:30367'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.deploy(project='network-operations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-10-04 12:36:08,847 [info] invoking function: {'method': 'GET', 'path': 'http://nuclio-network-operations-labeled-stream-creator.default-tenant.svc.cluster.local:8080/'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.invoke('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
