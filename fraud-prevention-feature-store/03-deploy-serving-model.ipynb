{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Serving\n",
    "\n",
    "In this part we will use MLRun's **serving runtime** to deploy our trained models from the previous stage a `Voting Ensemble` using **max vote** logic.\n",
    "We will also use MLRun's **Feature store** to receive the latest tag of the online **Feature Vector** we defined in the preveious stage.\n",
    "\n",
    "By the end of this tutorial youâ€™ll learn how to:\n",
    "- Define a model class to load our models, run preprocessing and predict on the data\n",
    "- Define Voting Ensemble function on top of our models\n",
    "- Test the serving function locally using our `mock server`\n",
    "- Deploy the function to the cluster and test it live"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we will make sure SciKit-Learn is installed in the correct version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -cikit-learn (/User/.pythonlibs/mlrun-extended/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -cikit-learn (/User/.pythonlibs/mlrun-extended/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-learn in /User/.pythonlibs/mlrun-extended/lib/python3.9/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /conda/envs/mlrun-extended/lib/python3.9/site-packages (from scikit-learn) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /conda/envs/mlrun-extended/lib/python3.9/site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /conda/envs/mlrun-extended/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /conda/envs/mlrun-extended/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -cikit-learn (/User/.pythonlibs/mlrun-extended/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Restart your kernel post installing.\n",
    "Secondly, since our work is done in this project scope, we will want to define the project itself for all our MLRun work in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'fraud-demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-02-09 15:27:15,984 [info] loaded project fraud-demo from MLRun DB\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "\n",
    "# Initialize the MLRun project object\n",
    "project = mlrun.get_or_create_project(project_name, context=\"./\", user_project=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Class\n",
    "- Load models\n",
    "- Predict from the feature store online service via the `source` key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cloudpickle import load\n",
    "from mlrun.serving.v2_serving import V2ModelServer\n",
    "\n",
    "class ClassifierModel(V2ModelServer):\n",
    "    \n",
    "    def load(self):\n",
    "        \"\"\"load and initialize the model and/or other elements\"\"\"\n",
    "        model_file, extra_data = self.get_model('.pkl')\n",
    "        self.model = load(open(model_file, 'rb'))\n",
    "        \n",
    "    def predict(self, body: dict) -> list:\n",
    "        \"\"\"Generate model predictions from sample\"\"\"\n",
    "        print(f\"Input -> {body['inputs']}\")\n",
    "        feats = np.asarray(body['inputs'])\n",
    "        result: np.ndarray = self.model.predict(feats)\n",
    "        return result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Serving Function\n",
    "\n",
    "MLRun serving can produce managed real-time serverless pipelines from various tasks, including MLRun models or standard model files.\n",
    "The pipelines use the Nuclio real-time serverless engine, which can be deployed anywhere.\n",
    "[Nuclio](https://nuclio.io/) is a high-performance open-source serverless framework that's focused on data, I/O, and compute-intensive workloads.\n",
    "\n",
    "The **EnrichmentVotingEnsemble** and the **EnrichmentModelRouter** router classes auto enrich the request with data from the feature store.\n",
    "the router input accept list of inference request (each request can be a dict or list of incoming features/keys), it enriches the request with data from the specified feature vector (`feature_vector_uri`).\n",
    "\n",
    "In many cases the features can have null values (None, NaN, Inf, ..), the `Enrichment` routers can substitute the null value with fixed or statistical value per feature, this is done through the `impute_policy` parameter which accepts the impute policy per feature (where `*` is used to specify the default), the value can be fixed number for constants or `$mean`, `$max`, `$min`, `$std`, `$count` for statistical values. to substitute the value with the equivalent feature stats (taken from the feature store).  \n",
    "\n",
    "In the code below we perform the following steps:\n",
    "\n",
    "- Gather ClassifierModel code from this notebook\n",
    "- Define `EnrichmentVotingEnsemble` - Max-Vote based ensemble with feature enrichment and imputing\n",
    "- Add the previously trained models to the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"917pt\" height=\"196pt\"\n",
       " viewBox=\"0.00 0.00 916.72 196.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 192)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-192 912.72,-192 912.72,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"423.39,-152.05 425.54,-152.15 427.67,-152.3 429.76,-152.49 431.82,-152.74 433.83,-153.03 435.79,-153.36 437.68,-153.75 439.5,-154.18 441.24,-154.65 442.9,-155.16 444.47,-155.71 445.95,-156.31 447.33,-156.94 448.6,-157.61 449.77,-158.31 450.83,-159.04 451.77,-159.8 452.61,-160.59 453.32,-161.41 453.93,-162.25 454.42,-163.11 454.79,-163.99 455.05,-164.89 455.2,-165.8 455.24,-166.72 455.17,-167.65 455,-168.59 454.73,-169.53 454.37,-170.47 453.91,-171.41 453.36,-172.35 452.73,-173.28 452.02,-174.2 451.24,-175.11 450.39,-176.01 449.47,-176.89 448.49,-177.75 447.46,-178.59 446.37,-179.41 445.24,-180.2 444.07,-180.96 442.86,-181.69 441.61,-182.39 440.34,-183.06 439.04,-183.69 437.72,-184.29 436.37,-184.84 435.01,-185.35 433.63,-185.82 432.24,-186.25 430.84,-186.64 429.43,-186.97 428.01,-187.26 426.59,-187.51 425.16,-187.7 423.73,-187.85 422.29,-187.95 420.86,-188 419.42,-188 417.99,-187.95 416.55,-187.85 415.12,-187.7 413.69,-187.51 412.27,-187.26 410.85,-186.97 409.44,-186.64 408.04,-186.25 406.65,-185.82 405.27,-185.35 403.91,-184.84 402.56,-184.29 401.24,-183.69 399.94,-183.06 398.66,-182.39 397.42,-181.69 396.21,-180.96 395.04,-180.2 393.91,-179.41 392.82,-178.59 391.79,-177.75 390.81,-176.89 389.89,-176.01 389.04,-175.11 388.26,-174.2 387.55,-173.28 386.92,-172.35 386.37,-171.41 385.91,-170.47 385.54,-169.53 385.27,-168.59 385.11,-167.65 385.04,-166.72 385.08,-165.8 385.23,-164.89 385.49,-163.99 385.86,-163.11 386.35,-162.25 386.95,-161.41 387.67,-160.59 388.5,-159.8 389.45,-159.04 390.51,-158.31 391.68,-157.61 392.95,-156.94 394.33,-156.31 395.8,-155.71 397.38,-155.16 399.04,-154.65 400.78,-154.18 402.6,-153.75 404.49,-153.36 406.45,-153.03 408.46,-152.74 410.51,-152.49 412.61,-152.3 414.74,-152.15 416.89,-152.05 419.05,-152 421.22,-152 423.39,-152.05\"/>\n",
       "<text text-anchor=\"middle\" x=\"420.14\" y=\"-166.3\" font-family=\"Times,serif\" font-size=\"14.00\">start</text>\n",
       "</g>\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title></title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"447.14,-86.54 447.14,-101.46 431.32,-112 408.96,-112 393.14,-101.46 393.14,-86.54 408.96,-76 431.32,-76 447.14,-86.54\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"451.14,-84.4 451.14,-103.6 432.53,-116 407.74,-116 389.14,-103.6 389.14,-84.4 407.74,-72 432.53,-72 451.14,-84.4\"/>\n",
       "</g>\n",
       "<!-- _start&#45;&gt; -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M420.14,-151.84C420.14,-144.16 420.14,-134.88 420.14,-126.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"423.64,-126.03 420.14,-116.03 416.64,-126.03 423.64,-126.03\"/>\n",
       "</g>\n",
       "<!-- transaction_fraud_top_rf -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>transaction_fraud_top_rf</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"124.14\" cy=\"-18\" rx=\"124.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"124.14\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">transaction_fraud_top_rf</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;transaction_fraud_top_rf -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>&#45;&gt;transaction_fraud_top_rf</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M389.02,-85.22C342.97,-73.71 255.48,-51.84 193.67,-36.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"194.15,-32.9 183.6,-33.87 192.45,-39.69 194.15,-32.9\"/>\n",
       "</g>\n",
       "<!-- transaction_fraud_top_xgboost -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>transaction_fraud_top_xgboost</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"420.14\" cy=\"-18\" rx=\"153.27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"420.14\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">transaction_fraud_top_xgboost</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;transaction_fraud_top_xgboost -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>&#45;&gt;transaction_fraud_top_xgboost</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M420.14,-71.99C420.14,-64.06 420.14,-54.91 420.14,-46.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"423.64,-46.31 420.14,-36.31 416.64,-46.31 423.64,-46.31\"/>\n",
       "</g>\n",
       "<!-- transaction_fraud_top_adaboost -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>transaction_fraud_top_adaboost</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"750.14\" cy=\"-18\" rx=\"158.67\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"750.14\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">transaction_fraud_top_adaboost</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;transaction_fraud_top_adaboost -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>&#45;&gt;transaction_fraud_top_adaboost</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M451.18,-86.04C501.19,-74.82 601.1,-52.42 671.62,-36.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"672.81,-39.93 681.8,-34.32 671.28,-33.1 672.81,-39.93\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f43b22ea880>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the serving function from our code above\n",
    "serving_fn = mlrun.code_to_function('transaction-fraud', kind='serving', image=\"mlrun/mlrun\").apply(mlrun.auto_mount())\n",
    "\n",
    "serving_fn.set_topology('router', 'mlrun.serving.routers.EnrichmentVotingEnsemble', name='VotingEnsemble',\n",
    "                        feature_vector_uri=\"transactions-fraud-short\", impute_policy={\"*\": \"$mean\"})\n",
    "\n",
    "model_names = [\n",
    "'transaction_fraud_rf',\n",
    "'transaction_fraud_xgboost',\n",
    "'transaction_fraud_adaboost'\n",
    "]\n",
    "\n",
    "for i, name in enumerate(model_names, start=1):\n",
    "    serving_fn.add_model(name, class_name=\"ClassifierModel\", model_path=project.get_artifact_uri(name))\n",
    "\n",
    "# Plot the ensemble configuration\n",
    "serving_fn.spec.graph.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the server locally\n",
    "\n",
    "Before deploying the serving function, we can test it in the current notebook and check the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mock server from the serving function\n",
    "local_server = serving_fn.to_mock_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an id for our test\n",
    "sample_id = 'C1000148617'\n",
    "\n",
    "model_inference_path = '/v2/models/infer'\n",
    "\n",
    "# Send our sample ID for predcition\n",
    "local_server.test(path=model_inference_path,\n",
    "            body={'inputs': [[sample_id]]})\n",
    "\n",
    "# notice the input vector is printed 3 times (once per child model) and is enriched with data from the feature store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the real-time feature vector directly\n",
    "\n",
    "We can also directly query the feature store values using the `get_online_feature_service` method, this method is used internally in the EnrichmentVotingEnsemble router class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun.feature_store as fstore\n",
    "\n",
    "# Create the online feature service\n",
    "svc = fstore.get_online_feature_service('transactions-fraud-short:latest', impute_policy={\"*\": \"$mean\"})\n",
    "\n",
    "# Get sample feature vector\n",
    "sample_fv = svc.get([{'source': sample_id}])\n",
    "sample_fv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the function on the kubernetes cluster\n",
    "\n",
    "We can now deploy the function, once deployed we will get a function with http trigger that can be called from other locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Enable model monitoring\n",
    "serving_fn.set_tracking()\n",
    "project.set_model_monitoring_credentials(os.getenv('V3IO_ACCESS_KEY'))\n",
    "\n",
    "# Deploy the serving function\n",
    "serving_fn.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Server\n",
    "\n",
    "We can test the serving function and examine the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an id for our test\n",
    "sample_id = 'C1000148617'\n",
    "\n",
    "model_inference_path = '/v2/models/infer'\n",
    "\n",
    "# Send our sample ID for predcition\n",
    "serving_fn.invoke(path=model_inference_path,\n",
    "                  body={'inputs': [[sample_id]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also directly query the feature store values, which is used in the enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate incoming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = mlrun.get_dataitem('https://s3.wasabisys.com/iguazio/data/fraud-demo-mlrun-fs-docs/data.csv').as_df()\n",
    "\n",
    "# use only first 50k\n",
    "data = data.sort_values(by='source', axis=0)[:50000]\n",
    "\n",
    "# keys\n",
    "sample_ids = data['source'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice, uniform\n",
    "from time import sleep\n",
    "\n",
    "# Sending random requests\n",
    "for _ in range(10):\n",
    "    data_point = choice(sample_ids)\n",
    "    try:\n",
    "        resp = serving_fn.invoke(path=model_inference_path, body={'inputs': [[data_point]]})\n",
    "        print(resp)\n",
    "        sleep(uniform(0.2, 1.7))\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Done!\n",
    "\n",
    "You've completed Part 3 of the deploying the serving function.\n",
    "Proceed to [Part 4](04-pipeline.ipynb) to learn how to automate ML Pipeline.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlrun-extended",
   "language": "python",
   "name": "conda-env-mlrun-extended-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
