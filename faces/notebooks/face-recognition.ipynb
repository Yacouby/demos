{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-mlrun-install\"></a>The tutorial uses MLRun to create a project, implement and execute an ML pipeline, and track the execution.\n",
    "(For more information about MLRun, see Step 1.)\n",
    "To use MLRun, you must first ensure that it's installed and running as a service on your platform cluster.\n",
    "Look for an `mlrun` service on the **Services** page of the platform dashboard.\n",
    "For more information and additional assistance, contact the Iguazio [support team](mailto:support@iguazio.com).\n",
    "\n",
    "To use MLRun from Jupyter Notebook, you need to run the following code to install the `mlrun` Python package.\n",
    "This needs to be done only once per Jupyter Notebook service.\n",
    "> **Note:** You must **restart the Jupyter kernel** to complete the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already installed: mlrun\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "import IPython\n",
    "\n",
    "required = {'mlrun'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "previously_installed = required.intersection(installed)\n",
    "\n",
    "if missing:\n",
    "    print(f'Installing {\",\".join(missing)}')\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
    "    print('Restarting kernel')\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel\n",
    "if previously_installed:\n",
    "    print(f'Already installed: {\",\".join(previously_installed)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the mlrun project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path: /User/mlrun/demos/faces/notebooks\n",
      "Project name: faces\n"
     ]
    }
   ],
   "source": [
    "from os import path, getenv\n",
    "from mlrun import new_project, mlconf\n",
    "\n",
    "#project_name = '-'.join(filter(None, ['getting-started-iris', getenv('V3IO_USERNAME', None)]))\n",
    "project_name = \"faces\"\n",
    "project_path = path.abspath('./')\n",
    "project = new_project(project_name, project_path)\n",
    "project.save()\n",
    "print(f'Project path: {project_path}\\nProject name: {project_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mlconf.artifact_path or path.abspath('./data')\n",
    "# {{run.uid}} will be substituted with the run id, so output will be written to different directoried per run\n",
    "artifact_path = path.join(out, '{{run.uid}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### declare encode-images function for encoding initial images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import mount_v3io, code_to_function\n",
    "encode_images_func = code_to_function('encode-images', kind='job', filename='functions/encode_images.py',image='aviaigz/ml-models:0.5.4')\n",
    "#encode_images_func.spec.build.base_image = 'aviaigz/ml-models:0.5.4'\n",
    "encode_images_func.deploy(with_mlrun=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### declare train function for training the encoded images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import mount_v3io, code_to_function\n",
    "train_func = code_to_function('train', kind='job', filename='functions/train.py',image='aviaigz/ml-models:0.5.4')\n",
    "#train_func.spec.build.base_image = 'aviaigz/ml-models:0.5.4'\n",
    "train_func.deploy(with_mlrun=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### declare face-prediction nuclio function for predicting face based on model created in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nuclio\n",
    "import os\n",
    "from mlrun import mount_v3io, code_to_function\n",
    "nuclio_face_prediction_func = code_to_function('nuclio-face-prediction', kind='nuclio', filename='nuclio-face-prediction.ipynb')\n",
    "# set the API/trigger, attach the home dir to the function\n",
    "nuclio_face_prediction_func.with_http(workers=2).apply(mount_v3io())\n",
    "\n",
    "# set environment variables\n",
    "nuclio_face_prediction_func.set_env('MODELS_PATH', '/User/mlrun/demos/faces/notebooks/functions/models.py')\n",
    "nuclio_face_prediction_func.set_env('MODEL_PATH', '/User/faces/artifacts/model.bst')\n",
    "nuclio_face_prediction_func.set_env('CLASSES_MAP', '/User/faces/artifacts/idx2name.csv')\n",
    "nuclio_face_prediction_func.set_env('V3IO_ACCESS_KEY', os.environ['V3IO_ACCESS_KEY'])\n",
    "nuclio_face_prediction_func.spec.build.base_image = 'mlrun/ml-models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### declare nuclio api-serving function for managing images requests and process face-prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nuclio\n",
    "import os\n",
    "from mlrun import mount_v3io, code_to_function\n",
    "nuclio_api_serving_func = code_to_function('nuclio-api-serving', kind='nuclio', filename='nuclio-api-serving.ipynb')\n",
    "# set the API/trigger, attach the home dir to the function\n",
    "nuclio_api_serving_func.with_http(workers=2).apply(mount_v3io())\n",
    "\n",
    "# set environment variables\n",
    "nuclio_api_serving_func.set_env('DATA_PATH' ,'/User/faces/dataset/')\n",
    "nuclio_api_serving_func.set_env('V3IO_ACCESS_KEY', os.environ['V3IO_ACCESS_KEY'])\n",
    "nuclio_api_serving_func.spec.build.base_image = 'mlrun/ml-models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the project functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACTS_PATH ='/User/faces/artifacts/'\n",
    "from mlrun import mount_v3io, code_to_function\n",
    "\n",
    "\n",
    "project.set_function(encode_images_func,name='encode-images')\n",
    "project.set_function(train_func,name = 'train')\n",
    "project.set_function(nuclio_face_prediction_func,name = 'nuclio-face-prediction')\n",
    "project.set_function(nuclio_api_serving_func,name = 'nuclio-api-serving')\n",
    "\n",
    "project.func('encode-images').apply(mount_v3io())\n",
    "project.func('train').apply(mount_v3io())\n",
    "project.func('nuclio-face-prediction').apply(mount_v3io())\n",
    "project.func('nuclio-api-serving').apply(mount_v3io())\n",
    "\n",
    "\n",
    "project.func('encode-images').set_env('PYTHONPATH', project_path)\n",
    "project.func('train').set_env('PYTHONPATH', project_path)\n",
    "project.func('nuclio-face-prediction').set_env('PYTHONPATH', project_path)\n",
    "project.func('nuclio-api-serving').set_env('PYTHONPATH', project_path)\n",
    "\n",
    "\n",
    "project.func('encode-images').spec.artifact_path = ARTIFACTS_PATH\n",
    "project.func('train').spec.artifact_path = ARTIFACTS_PATH\n",
    "project.func('nuclio-face-prediction').spec.artifact_path = ARTIFACTS_PATH\n",
    "project.func('nuclio-api-serving').spec.artifact_path = ARTIFACTS_PATH\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-step-create-n-run-ml-pipeline\"></a>\n",
    "## Create and Run a Fully Automated ML Pipeline\n",
    "\n",
    "You're now ready to create a full ML pipeline.\n",
    "This is done by using [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/), which is integrated into the Iguazio Data Science Platform.\n",
    "Kubeflow Pipelines is an open-source framework for building and deploying portable, scalable machine-learning workflows based on Docker containers.\n",
    "MLRun leverages this framework to take your existing code and deploy it as steps in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /User/mlrun/demos/faces/notebooks/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {path.join(project_path, 'workflow.py')}\n",
    "\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io\n",
    "from os import getenv, path\n",
    "\n",
    "DATA_PATH ='/User/faces/dataset/'\n",
    "ARTIFACTS_PATH ='/User/faces/artifacts/'\n",
    "MODELS_PATH = '/User/mlrun/demos/faces/notebooks/functions/models.py'\n",
    "FRAMES_URL = 'framesd:8081'\n",
    "V3IO_ACCESS_KEY = getenv('V3IO_ACCESS_KEY')\n",
    "USER_NAME = getenv('V3IO_USERNAME')\n",
    "ENCODINGS_PATH = '/'.join([USER_NAME,'faces','encodings']) \n",
    "WEB_API = \"http://v3io-webapi:8081\"\n",
    "\n",
    "\n",
    "funcs = {}\n",
    "project_path = path.abspath('./')\n",
    "faces_params = {'data_path' : DATA_PATH,\n",
    "                'artifacts_path': ARTIFACTS_PATH,\n",
    "                'models_path': MODELS_PATH,\n",
    "                'frames_url': FRAMES_URL,\n",
    "                'token' : V3IO_ACCESS_KEY, \n",
    "                'encodings_path': ENCODINGS_PATH }\n",
    "\n",
    "# Configure function resources and local settings\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    project_path = path.abspath('./')\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())\n",
    "        f.set_env('PYTHONPATH', project_path)\n",
    "        f.spec.artifact_path = ARTIFACTS_PATH\n",
    "        \n",
    "        \n",
    "        \n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(\n",
    "    name = \"faces-pipeline\",\n",
    "    description = \"faces demo pipeline\"\n",
    ")\n",
    "def kfpipeline():\n",
    "    # encode images\n",
    "    encode = funcs['encode-images'].as_step(\n",
    "        name=\"encode_images\",\n",
    "        params=faces_params,\n",
    "        outputs=['encode']\n",
    "    )\n",
    "    \n",
    "    # train the model based on the images\n",
    "    train = funcs['train'].as_step(\n",
    "        name=\"train\",\n",
    "        params = faces_params,\n",
    "        inputs={'table': encode.outputs},                       \n",
    "        outputs=['training']\n",
    "    )\n",
    "    # deploy the model as nuclio function\n",
    "    nuclio_face_prediction = funcs['nuclio-face-prediction'].deploy_step(                \n",
    "        models={\"nuclio-face-prediction\": train.outputs['training']}        \n",
    "    )    \n",
    "    \n",
    "    # deploy api serving as nuclio function\n",
    "    nuclio_api_serving = funcs['nuclio-api-serving'].deploy_step()\n",
    "    nuclio_api_serving.after(nuclio_face_prediction)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-register-workflow\"></a>\n",
    "#### Register the Workflow\n",
    "\n",
    "Use the `set_workflow` MLRun project method to register your workflow with MLRun.\n",
    "The following code sets the `name` parameter to the selected workflow name (\"main\") and the `code` parameter to the name of the workflow file that is found in your project directory (**workflow.py**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file as \"main\"\n",
    "project.set_workflow('main', 'workflow.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.app-lab-eks-b84.iguazio-cd1.com/pipelines/#/experiments/details/39ffb197-85f5-4144-8090-3f56ecd50911\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.app-lab-eks-b84.iguazio-cd1.com/pipelines/#/runs/details/dc581f66-c692-42ba-b0ea-4f174c51e530\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-11-30 14:21:53,149 [info] Pipeline run id=dc581f66-c692-42ba-b0ea-4f174c51e530, check UI or DB for progress\n"
     ]
    }
   ],
   "source": [
    "run_id = project.run(\n",
    "    'main',\n",
    "    arguments={}, \n",
    "    \n",
    "    artifact_path=path.abspath(path.join('pipeline','{{workflow.uid}}'),\n",
    "    \n",
    "                              )\n",
    "    ,dirty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
